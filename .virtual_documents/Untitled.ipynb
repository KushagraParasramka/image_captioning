import streamlit as st
import joblib as jbl
import os
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from textwrap import wrap

# Load the model and tokenizer
caption_model = jbl.load("image_caption_model.joblib")
tokenizer = Tokenizer()

# Function to preprocess text
def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

def predict_caption(model, image_path, tokenizer, max_length):
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img)
    img_array = img_array / 255.
    feature = np.expand_dims(img_array, axis=0)
    
    in_text = "startseq"
    for _ in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], maxlen=max_length)
        y_pred = model.predict([feature, sequence])
        y_pred = np.argmax(y_pred)
        word = idx_to_word(y_pred, tokenizer)
        if word is None or word == 'endseq':
            break
        in_text += " " + word
    return in_text.strip()

def display_image(image, caption):
    st.image(image, caption=caption, width=300)

def main():
    st.title("Image Captioning App")

    uploaded_file = st.file_uploader("Upload Image", type=["jpg", "jpeg", "png"])
    if uploaded_file is not None:
        image = load_img(uploaded_file, target_size=(224, 224))
        st.image(image, caption='Uploaded Image', width=300)
        
        if st.button("Generate Caption"):
            caption = predict_caption(caption_model, uploaded_file, tokenizer, 34)
            caption = caption.lstrip("startseq ").rstrip("endseq")
            st.write("Generated Caption:", caption)

if __name__ == "__main__":
    main()







