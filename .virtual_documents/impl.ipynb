import joblib as jbl
caption_model = jbl.load("image_caption_model.joblib")


from tensorflow.keras.applications import VGG16, ResNet50, DenseNet201
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
import os
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import matplotlib.pyplot as plt
from textwrap import wrap
import seaborn as sns
import pandas as pd
plt.rcParams['font.size'] = 12
sns.set_style("dark")
# warnings.filterwarnings('ignore')


tokenizer = Tokenizer()


data = pd.read_csv("./archive/captions.txt")


def text_preprocessing(data):
    data['caption'] = data['caption'].apply(lambda x: x.lower())
    data['caption'] = data['caption'].apply(lambda x: x.replace("[^A-Za-z]",""))
    data['caption'] = data['caption'].apply(lambda x: x.replace("\s+"," "))
    data['caption'] = data['caption'].apply(lambda x: " ".join([word for word in x.split() if len(word)>1]))
    data['caption'] = "startseq "+data['caption']+" endseq"
    return data


data = text_preprocessing(data)
captions = data['caption'].tolist()


tokenizer = Tokenizer()
tokenizer.fit_on_texts(captions)


model = DenseNet201()
fe = Model(inputs=model.input, outputs=model.layers[-2].output)

img_size = 224
features = {}


image_path = './'
image = 'img8.jpeg'
img = load_img(os.path.join(image_path,image),target_size=(img_size,img_size))
img = img_to_array(img)
img = img/255.
img = np.expand_dims(img,axis=0)
feature = fe.predict(img, verbose=0)
features[image] = feature


def idx_to_word(integer,tokenizer):
    
    for word, index in tokenizer.word_index.items():
        if index==integer:
            return word
    return None


def predict_caption(model, image, tokenizer, max_length, features):
    
    feature = features[image]
    in_text = "startseq"
    for i in range(max_length):
        
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], max_length)

        y_pred = model.predict([feature,sequence])
        y_pred = np.argmax(y_pred)
        print(y_pred)
        word = idx_to_word(y_pred, tokenizer)
        
        if word is None:
            break
            
        in_text+= " " + word
        
        if word == 'endseq':
            break
            
    return in_text 



    
caption = predict_caption(caption_model, image, tokenizer, 34, features)
caption = caption.lstrip("startseq ").rstrip("endseq")
caption



def readImage(path,img_size=224):
    img = load_img(path,color_mode='rgb',target_size=(img_size,img_size))
    img = img_to_array(img)
    img = img/255.
    
    return img

def display_image(image,caption):
    
    plt.figure(figsize = (3 , 3))
    image = readImage(f"./{image}")
    plt.imshow(image)
    plt.title("\n".join(wrap(caption, 20)))
    plt.axis("off")






display_image(image,caption)









